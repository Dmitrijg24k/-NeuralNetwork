{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"Course 1 - Part 8 - Lesson 4 - Notebook.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dmitrijg24k/-NeuralNetwork/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22Course_1_Part_8_Lesson_4_Notebook_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXZT2UsyIVe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575202f1-63ce-4285-d259-0dd77d0a464b"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-07 07:35:09--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.112, 172.217.164.176, 172.217.2.112, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   321MB/s    in 0.2s    \n",
            "\n",
            "2021-02-07 07:35:10 (321 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mLij6qde6Ox"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n",
        "    -O /tmp/validation-horse-or-human.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9brUxyTpYZHy"
      },
      "source": [
        "Следующий код Python будет использовать библиотеку ОС для использования библиотек операционной системы, предоставляя вам доступ к файловой системе и библиотеке zipfile, позволяющей распаковать данные. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLy3pthUS0D2"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-qUPyfO7Qr8"
      },
      "source": [
        "Содержимое .zip извлекается в базовый каталог `/tmp/horse-or-human`, каждый из которых, в свою очередь, содержит подкаталоги лошадей и людей.\n",
        "\n",
        "В этом примере нужно обратить внимание на одну вещь: мы не обозначаем изображения явно как лошади или люди. Если вы помните в примере рукописных цифр ранее, мы пометили «это 1», «это 7» и т. Д. Позже вы увидите, что используется нечто, называемое ImageGenerator - он читает изображения из подкаталогов и сразу помечает их именами этого подкаталога. Так, например, у вас будет каталог 'training', содержащий каталог 'horse' и каталог 'people'. ImageGenerator создает массив данных из изображений, размеченными в соответствии с этими названиями, сокращая этап кодирования.\n",
        "\n",
        "Давайте определим каждый из этих каталогов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR_M9nWN-K8B"
      },
      "source": [
        "train_dir = os.path.join('/tmp/cats_and_dogs_filtered/train')\n",
        "validation_dir = os.path.join('/tmp/cats_and_dogs_filtered/validation')\n",
        "train_cats_dir = os.path.join('/tmp/cats_and_dogs_filtered/train/cats')\n",
        "train_dogs_dir = os.path.join('/tmp/cats_and_dogs_filtered/train/dogs')\n",
        "validation_cats_dir = os.path.join('/tmp/cats_and_dogs_filtered/validation/cats')\n",
        "validation_dogs_dir = os.path.join('/tmp/cats_and_dogs_filtered/validation/dogs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP1SjhyJ7cyf"
      },
      "source": [
        "Теперь давайте посмотрим, как выглядят имена файлов в каталогах обучения horses и humans и сколько там всего файлов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPdTsF_H7klu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf48a72-b8cd-4947-dc18-7288d442bee7"
      },
      "source": [
        "train_cats_names = os.listdir(train_cats_dir)\n",
        "print(train_cats_names[:10])\n",
        "print('total training cats images:', len(os.listdir(train_cats_dir)))\n",
        "\n",
        "train_dogs_names = os.listdir(train_dogs_dir)\n",
        "print(train_dogs_names[:10])\n",
        "print('total training dogs images:', len(os.listdir(train_dogs_dir)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cat.3.jpg', 'cat.313.jpg', 'cat.933.jpg', 'cat.916.jpg', 'cat.82.jpg', 'cat.75.jpg', 'cat.660.jpg', 'cat.371.jpg', 'cat.996.jpg', 'cat.846.jpg']\n",
            "total training cats images: 1000\n",
            "['dog.715.jpg', 'dog.717.jpg', 'dog.949.jpg', 'dog.861.jpg', 'dog.341.jpg', 'dog.469.jpg', 'dog.566.jpg', 'dog.265.jpg', 'dog.711.jpg', 'dog.448.jpg']\n",
            "total training dogs images: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqInfZzgeGGF"
      },
      "source": [
        "# Установите Matplotlib fig и его размер, чтобы вывести 4x4 картинок\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Параметры для нашего графика; Мы будем выводить изображения в конфигурации 4х4\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "# Index for iterating over images\n",
        "pic_index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkXfLJHW8WVs"
      },
      "source": [
        "Теперь покажите пакет из 8 изображений лошадей и 8 человек. Каждый раз, запуская эту ячейку вы увидите новый пакет:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shGtinzT8Z6M"
      },
      "source": [
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "pic_index += 8\n",
        "next_horse_pix = [os.path.join(train_horse_dir, fname) \n",
        "                for fname in train_horse_names[pic_index-8:pic_index]]\n",
        "next_human_pix = [os.path.join(train_human_dir, fname) \n",
        "                for fname in train_human_names[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_horse_pix+next_human_pix):\n",
        "  # Set up subplot; Индексы subplot начинаются с 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Не показывать оси (или линии сетки)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oqBkNBJmtUv"
      },
      "source": [
        "##Создание маленькой модели с нуля\n",
        "Но прежде чем мы продолжим, давайте определим модель:\n",
        "\n",
        "Шаг 1 импортируем tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvfZg3LQbD-5"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnhYCP4tdqjC"
      },
      "source": [
        "Затем мы добавляем сверточные слои, как в предыдущем примере, и вытягиваем конечный результат в одномерный массив для подачи в полносвязные слои.\n",
        "\n",
        "Наконец мы добавляем плотно связанные слои.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gokG5HKpdtzm"
      },
      "source": [
        "Обратите внимание, что, поскольку мы сталкиваемся с проблемой классификации двух классов, то есть проблемой двоичной классификации, мы завершим нашу сеть с помощью функции активации [*sigmoid* activation](https://wikipedia.org/wiki/Sigmoid_function), так что выход нашей сети - это один скаляр от 0 до 1, показывающий вероятность того, что текущее изображение относится к классу 1 (в противоположность классу 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PixZ2s5QbYQ3"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Обратите внимание, что входной формой является желаемый размер изображения 150x150 с 3 байтами цвета\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Только 1 выходной нейрон. Он будет содержать значение от 0 до 1, где 0 для 1 класса («лошади») и 1 для другого («люди»)\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9EaFDP5srBa"
      },
      "source": [
        "\n",
        "метод model.summary() печатает сводку нашей нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZKj8392nbgP"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmtkTn06pKxF"
      },
      "source": [
        "The \"output shape\" column shows how the size of your feature map evolves in each successive layer. The convolution layers reduce the size of the feature maps by a bit due to padding, and each pooling layer halves the dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEkKSpZlvJXA"
      },
      "source": [
        "Столбец «output shape» показывает, как изменяется размер вашей карты признаков в каждом следующем слое. Слои свертки немного уменьшают размер карт признаков из-за потерь на краях изображений, и каждый слой пуллинга сокращает размерности вдвое.\n",
        "\n",
        "Далее мы настроим спецификации для обучения модели. Мы будем тренировать нашу модель с функцией потерь `binary_crossentropy`, потому что это задача бинарной классификации, а наша последняя активация - сигмоида. (Для получения дополнительной информации о показателях потерь см. [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/descending-into-ml/video-lecture).) Мы будем использовать Оптимизатор `rmsprop` со скоростью обучения 0,001. Во время обучения мы хотим отслеживать точность классификации. ПРИМЕЧАНИЕ: в этом случае использование алгоритма оптимизации [RMSprop](https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp)  предпочтительнее [stochastic gradient descent](https://developers.google.com/machine-learning/glossary/#SGD) (SGD), потому что RMSprop автоматически настраивает скорость обучения для нас. (другие оптимизаторы, такие как [Adam](https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam) и [Adagrad](https://developers.google.com/machine-learning/glossary/#AdaGrad) также автоматически адаптируют скорость обучения во время обучения, и будут работать здесь так же хорошо.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DHWhFP_uhq3"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn9m9D3UimHM"
      },
      "source": [
        "###Предварительная обработка данных\n",
        "Давайте настроим генераторы данных, которые будут читать изображения в наших исходных папках, преобразовывать их в тензоры `float32` и подавать их (с их метками) в нашу сеть. У нас будет один генератор для обучающих изображений и один для проверочных изображений. Наши генераторы будут выдавать партии изображений размером 150x150 и их метки (двоичные).\n",
        "\n",
        "Как вы уже знаете, данные, поступающие в нейронные сети, обычно должны каким-то образом нормализоваться, чтобы сделать их более пригодными для обработки сетью. В нашем случае мы будем предварительно обрабатывать наши изображения путем нормализации значений пикселей, чтобы они находились в диапазоне `[0, 1]` (изначально все значения находятся в дипазоне `[0, 255]`).\n",
        "\n",
        "В Keras это можно сделать с помощью класса `keras.preprocessing.image.ImageDataGenerator` с использованием параметра `rescale`. Этот класс `ImageDataGenerator` позволяет создавать экземпляры генераторов пакетов дополненных изображений (и их меток) с помощью `.flow(data, label` или `.flow_from_directory(dirname)`. Затем эти генераторы можно использовать с методами модели Keras, которые принимают генераторы данных в качестве входных данных: `fit_generator, evaluate_generator, и predict_generator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClebU9NJg99G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35db60eb-2f60-4739-8005-1fd5257f3e79"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Все пиксели изображения будут пересчитаны 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Поток обучающих изображений в партиях по 128 с использованием генератора train_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # Это исходный каталог для тренировочных изображений\n",
        "        target_size=(150, 150),  # все изображения будут изменены до 150x150\n",
        "        batch_size=20,\n",
        "        # поскольку мы используем функцию потерь binary_crossentropy, нам нужны двоичные метки\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,  # Это исходный каталог для проверочных изображений\n",
        "        target_size=(150, 150),  # все изображения будут изменены до 150x150\n",
        "        batch_size=20,\n",
        "        # поскольку мы используем функцию потерь binary_crossentropy, нам нужны двоичные метки\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu3Jdwkjwax4"
      },
      "source": [
        "### Тренировка\n",
        "Давайте потренируемся 15 эпох - это может занять несколько минут. Обратите внимание на значения в эпохе.\n",
        "\n",
        "`Loss и accuracy` являются отличными показателями прогресса обучения. Делается предположение о классификации обучающих данных, а затем оно сравнивается с известной меткой, вычисляя результат. `accuracy` - это доля правильных догадок."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb1_lgobv81m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "outputId": "e1fb96b8-0f21-43ca-8248-ba6473858967"
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=50,  \n",
        "      epochs=15,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=50)\n",
        "acc      = history.history[     'acc' ]\n",
        "val_acc  = history.history[ 'val_acc' ]\n",
        "loss     = history.history[    'loss' ]\n",
        "val_loss = history.history['val_loss' ]\n",
        "epochs   = range(len(acc))\n",
        "plt.plot  ( epochs, acc )\n",
        "plt.plot  ( epochs, val_acc )\n",
        "plt.title ('Точность обучения на тренировочных и на проверочных изображениях')\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\r 1/50 [..............................] - ETA: 3s - loss: 0.0616 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 5s 107ms/step - loss: 0.1231 - acc: 0.9650 - val_loss: 0.8515 - val_acc: 0.7280\n",
            "Epoch 2/15\n",
            "50/50 [==============================] - 5s 108ms/step - loss: 0.1086 - acc: 0.9600 - val_loss: 1.0166 - val_acc: 0.7490\n",
            "Epoch 3/15\n",
            "50/50 [==============================] - 5s 105ms/step - loss: 0.0853 - acc: 0.9740 - val_loss: 1.0345 - val_acc: 0.7150\n",
            "Epoch 4/15\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.0958 - acc: 0.9660 - val_loss: 0.9746 - val_acc: 0.7330\n",
            "Epoch 5/15\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.0843 - acc: 0.9720 - val_loss: 1.0150 - val_acc: 0.7400\n",
            "Epoch 6/15\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.0670 - acc: 0.9840 - val_loss: 1.1272 - val_acc: 0.7290\n",
            "Epoch 7/15\n",
            "50/50 [==============================] - 5s 109ms/step - loss: 0.0677 - acc: 0.9790 - val_loss: 1.3117 - val_acc: 0.7160\n",
            "Epoch 8/15\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.0355 - acc: 0.9900 - val_loss: 1.7523 - val_acc: 0.7140\n",
            "Epoch 9/15\n",
            "50/50 [==============================] - 5s 107ms/step - loss: 0.0565 - acc: 0.9820 - val_loss: 1.2616 - val_acc: 0.7170\n",
            "Epoch 10/15\n",
            "50/50 [==============================] - 5s 108ms/step - loss: 0.0408 - acc: 0.9880 - val_loss: 1.4152 - val_acc: 0.7150\n",
            "Epoch 11/15\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.0445 - acc: 0.9890 - val_loss: 1.6998 - val_acc: 0.6910\n",
            "Epoch 12/15\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.0341 - acc: 0.9890 - val_loss: 1.3305 - val_acc: 0.7270\n",
            "Epoch 13/15\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.0189 - acc: 0.9930 - val_loss: 2.8929 - val_acc: 0.6900\n",
            "Epoch 14/15\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.0266 - acc: 0.9890 - val_loss: 2.3083 - val_acc: 0.7180\n",
            "Epoch 15/15\n",
            "50/50 [==============================] - 5s 105ms/step - loss: 0.0443 - acc: 0.9860 - val_loss: 1.9538 - val_acc: 0.7530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6vSHzPR2ghH"
      },
      "source": [
        "###Запуск модели\n",
        "Давайте теперь посмотрим как на самом деле работает предсказание с использованием модели. Этот код позволит вам выбрать 1 или более файлов из вашей файловой системы, затем он загрузит их и проведет их через модель, указав, является ли объект лошадью или человеком."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoWp43WxJDNT"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # Прогнозирование изображений\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a human\")\n",
        "  else:\n",
        "    print(fn + \" is a horse\")\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8EHQyWGDvWz"
      },
      "source": [
        "###Визуализация промежуточных представлений\n",
        "Чтобы понять, какие признаки выявил наш коннет, нужно сделать одну интересную вещь - визуализировать, как преобразуется вход при его прохождении через коннет.\n",
        "\n",
        "Давайте выберем случайное изображение из обучающего набора, а затем сгенерируем фигуру, где каждая строка является выходом слоя, а каждое изображение в строке является специальным фильтром в этой выходной карте объектов. Перезапустите эту ячейку, чтобы получить промежуточные представления для различных обучающих изображений."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5tES8rXFjux"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "train_horse_names = os.listdir(train_horse_dir)\n",
        "print(train_horse_names[:10])\n",
        "\n",
        "train_human_names = os.listdir(train_human_dir)\n",
        "\n",
        "# определим новую модель, которая будет принимать изображение в качестве ввода и выводить\n",
        "# промежуточные представления для всех слоев в  модели, начиная с первого.\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "# подготовим случайное входное изображение из тренировочного набора.\n",
        "horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
        "human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
        "img_path = random.choice(horse_img_files + human_img_files)\n",
        "\n",
        "img = load_img(img_path, target_size=(150, 150)) \n",
        "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Масштабируем в 1/255\n",
        "x /= 255\n",
        "\n",
        "# пропустим наше изображение через нашу сеть, получив таким образом все\n",
        "# промежуточные представления для этого изображения.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# Это названия слоев, поэтому они могут быть частью нашего чертежа.\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# Теперь давайте покажем наши представления\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Просто делаем это для слоев conv / maxpool, а не для полностью связанных слоев\n",
        "    n_features = feature_map.shape[-1]  # Количество признаков на карте признаков\n",
        "    # Карта объектов имеет форму (1, size, size, n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # Мы разместим наши изображения в этой матрице\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "      # Постобработка функции\n",
        "      x = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      # поместим каждый фильтр в большую горизонтальную сетку\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "    # Показать сетку\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuqK2arJL0wo"
      },
      "source": [
        "Как вы можете видеть, мы переходим от необработанных пикселей изображений к все более абстрактным и компактным представлениям. Представления начинают выделять то, на что обращает внимание сеть, и они показывают, что все меньше и меньше признаков «активируются»; Большинство из них обнуляются. Это называется 'sparsity'. Разреженность представлений является ключевой особенностью глубокого обучения.\n",
        "\n",
        "Эти представления несут все меньше информации об исходных пикселях изображения, но все более уточняют информацию о классе изображения. Вы можете представлять себе convNet (или глубокую сеть в целом) как о канале дистилляции информации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4IBgYCYooGD"
      },
      "source": [
        "##Очистить\n",
        "Перед каждым выполнением упражнения запустите эту ячейку, чтобы завершить работу ядра и освободить ресурсы памяти:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "651IgjLyo-Jx"
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}